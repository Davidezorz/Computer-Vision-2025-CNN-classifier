import torch
import torch.nn as nn
import math
from . import parser


"""
╭ CONVENTIONS ────────────────────────────────────────────────────────────────╮
│ ├─• B        ▶ batch size                                                   │
│ ├─• H        ▶ height of the image                                          │
│ ├─• W        ▶ width of the image                                           │
│ ╰─• C        ▶ number of channerls                                          │
╰─────────────────────────────────────────────────────────────────────────────╯
"""


class CNN(nn.Module):
    """
    Dynamic Convolutional Neural Network builder.

    Constructs a sequential PyTorch model from a list of configuration 
    dictionaries. It manages the transition of tensor shapes (spatial -> flat)
    automatically, removing the need for manual dimension calculations between
    blocks.

    Args:
        image_dims (tuple): Input image dimensions (could also be a tensor)
                            Supported formats: (H, W) or (C, H, W).
                            If (H, W) is provided, C=1 is assumed (grayscale).
        configs (list):     Ordered list of layer configurations. 
                            Typically generated by 'convParser', but can be 
                            built manually.
                            
                            Required keys per config dict:
                            - 'category': 'conv', 'linear', 'function', 'skip'
                            - 'class':    The PyTorch class (e.g., nn.Conv2d)
                            - 'args':     Dict of arguments for that class
                            
                            Note: For manual skip connections, you must manage
                            SkipStore, SkipAdd and SkipHandle classes yourself.

                            Note:  when 'in_channels' (in conv layers) and 
                            'in_features' (in linear layers) are equal to -1,
                            the values will be inferred.
        
        name (string):      Name of the network, used in save/load parameters
        init_type (class):  Funtion for wheights initialization
        init_conf (dict):   Arguments for the config function. Is a dict with 
                            the following keys and values:
                              - 'conv': dict with arguments for convolutions 
                                        initialization
                              - 'linear': dict with arguments for linear 
                                          layerinitialization

    Example:
        import torch.nn as nn
        configs = [
            {'category': 'conv',   'class': nn.Conv2d,                           
             'args': {'in_channels': -1, 'out_channels': 6, 'kernel_size': (5,5)
                      'padding': (2,2),  'stride': (1,1),  'dilation': (1,1)}},
            
            {'category': 'function', 'class': nn.ReLU, 'args': {}},
            
            {'category': 'function', 'class': nn.Flatten, 'args': {}},

            {'category': 'linear', 'class': nn.Linear,   
             'args': {'in_features': -1, 'out_features': 10}}
        ]
        model = CNN(image_dims=(28, 28), configs=configs)
    """

    def __init__(self, image_dims, configs: dict, name: str = 'CNN',
                 init_type = nn.init.kaiming_uniform_,
                 init_conf={'conv': {}, 'linear': {}}):
        super().__init__()
        self.name = name
        self.init_type = init_type
        self.init_conf = init_conf

        blocks = []
        image_dims = list(image_dims)

        self.current_dims = image_dims if len(image_dims)>2 else [1]+image_dims 
        self.in_dims = self.current_dims.copy()
        print(f"{self.name}\n{'in_dims':<12} {self.current_dims}")

        for config in configs:                                                  # For each config container
            self._inferredOutDim(config['args'], config['category'])            # ◀── Updates self.current_dims
            module = config['class'](**config['args'])                          # ◀─┬ Add the module cratedusing 
            blocks.append(module)                                               # ◀─┴ the correct arguments

            print(f"{config['type']:<12} {self.current_dims}")

        self.blocks    = nn.ModuleList(blocks)
        self.apply(self._initWeights)


    def _inferredOutDim(self, kwargs, category):
        """ Updates self.current_dims based on the layer type and
        infers missing input arguments (e.g., in_channels=-1)."""
        if category == 'conv':
            C, H, W = self.current_dims                                         # ◀── Unpack current shape
            if kwargs.get('in_channels') == -1:                                 #   ╭ Auto-fill input channels
                kwargs['in_channels'] = C                                       # ◀─┴ if not provided
            self.current_dims[0] = kwargs.get('out_channels', C)                # ◀─┬ Update C
            self.current_dims[1] = self._outDim([H, W], kwargs, 0)              # ◀─┼ Update H
            self.current_dims[2] = self._outDim([H, W], kwargs, 1)              # ◀─┴ Update W
            
        elif category == 'linear':                                              #   ╭ If we hit a Linear layer, the input 
            if kwargs.get('in_features') == -1:                                 # ◀─┼ is the flattened previous volume
                kwargs['in_features'] = math.prod(self.current_dims)            # ◀─┴ Calculates C*H*W
            self.current_dims = [kwargs['out_features']]                        # ◀── collapse everything into a 1D feature vector



    def _outDim(self, in_dim, kwargs, idx):
        """ Calculates output spatial dimension: 
        https://docs.pytorch.org/docs/stable/generated/torch.nn.Conv2d.html """ 
        coef1 = in_dim[idx] + 2*kwargs['padding'][idx]
        coef2 = kwargs['dilation'][idx] * (kwargs['kernel_size'][idx]-1)
        coef3 = (coef1 - coef2 - 1)/kwargs['stride'][idx]

        return math.floor(coef3 + 1)


    def _initWeights(self, module):                                             # ◀─┬ Applies Kaiming initialization 
        if isinstance(module, nn.Linear):                                       #   ◀ Initialize Linear Layers
            self.init_type(module.weight, **self.init_conf['linear'])           #   │            
            if module.bias is not None:                                         #   │                 
                nn.init.constant_(module.bias, 0)                               #   │
        elif isinstance(module, nn.Conv2d):                                     #   ◀ Initialize Convolutional Layers
            self.init_type(module.weight, **self.init_conf['conv'])             #   │            
            if module.bias is not None:                                         #   │                  
                nn.init.constant_(module.bias, 0)                               #   ╯


    def forward(self, x):
        if x.ndim < 4:                                                          #   ╭ Handle single image input
            x = x.view(1, *self.in_dims)                                        # ◀─┴ Reshape -> 1 C H W
        #print('\nforward\n')
        #print(f"{-1}: {x.shape}")
        for i, block in enumerate(self.blocks[:-1]):                            #   ╭ Apply all 
            x = block(x)                                                        # ◀─┴ Blocks
            # print(f"{i}: {x.shape}") 

        logits = self.blocks[-1](x)                                             #   ╭ compute and return the 
        return logits                                                           # ◀─┴ last layer (Logits)
    
    
    @torch.no_grad()
    def predict(self, x):                                                       # ◀┬─ performs inference by
        self.eval()                                                             #  │  taking the most probable
        logits = self(x)                                                        #  │  label (doens't compute 
        return logits.argmax(dim=-1)                                            #  ╯  the softamx)


    @torch.no_grad()
    def probabilities(self, x):                                                 # ◀┬─ compute input labels 
        self.eval()                                                             #  │  probabilities
        logits = self(x)                                                        #  │  
        probs = torch.softmax(logits, dim=-1)                                   #  │ 
        return probs                                                            #  ╯
    

    def save(self, folder='.weights/', name=None):                              # ◀┬─ save model 
        name = name if name else self.name                                      #  │  weights
        file = folder + name + '.pth'                                           #  │  
        torch.save(self.state_dict(), file)                                     #  ╯


    def load(self, folder='.weights/', name=None):                              # ◀┬─ load model
        name = name if name else self.name                                      #  │  weights
        file = folder + name + '.pth'                                           #  │  
        try:                                                                    #  │ 
            self.load_state_dict(torch.load(file, weights_only=True))           #  │
            print('model loaded')                                               #  │
        except Exception as e:                                                  #  │
            print("Model weights not avaiable \n\n", e)                         #  ╯